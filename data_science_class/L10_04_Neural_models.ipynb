{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/my_val.pkl', 'rb') as f:\n",
    "    data = joblib.load(f)\n",
    "locals().update(data)\n",
    "del data\n",
    "np.random.seed(123)\n",
    "\n",
    "test = pd.read_csv('data/test_ver02.csv', index_col='STU_ID')\n",
    "test = test.drop(columns='F3ONET2CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler?\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax = MinMaxScaler()\n",
    "x_tr = minmax.fit_transform(x)\n",
    "val_x_tr = minmax.transform(val_x)\n",
    "test_tr = minmax.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2class = {}\n",
    "for i, v in enumerate(y.unique()):\n",
    "    idx2class[i] = v\n",
    "class2idx = {v:i for i, v in idx2class.items()}\n",
    "y_tr = y.replace(class2idx)\n",
    "val_y_tr = val_y.replace(class2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               19456     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                660       \n",
      "=================================================================\n",
      "Total params: 30,452\n",
      "Trainable params: 30,452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_nn = Sequential([\n",
    "            Input(shape=(x_tr.shape[1],)),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(y_tr.nunique(), activation='softmax')\n",
    "    ])\n",
    "my_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "59/59 [==============================] - 0s 625us/step - loss: 2.7810 - acc: 0.1562\n",
      "Epoch 2/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 2.6065 - acc: 0.1863\n",
      "Epoch 3/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 2.5265 - acc: 0.2065\n",
      "Epoch 4/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 2.4738 - acc: 0.2174\n",
      "Epoch 5/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 2.4401 - acc: 0.2313\n",
      "Epoch 6/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 2.4161 - acc: 0.2336\n",
      "Epoch 7/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 2.3947 - acc: 0.2431\n",
      "Epoch 8/100\n",
      "59/59 [==============================] - 0s 584us/step - loss: 2.3790 - acc: 0.2473\n",
      "Epoch 9/100\n",
      "59/59 [==============================] - 0s 575us/step - loss: 2.3632 - acc: 0.2510\n",
      "Epoch 10/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 2.3483 - acc: 0.2556\n",
      "Epoch 11/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 2.3294 - acc: 0.2616\n",
      "Epoch 12/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 2.3176 - acc: 0.2608\n",
      "Epoch 13/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 2.3067 - acc: 0.2691\n",
      "Epoch 14/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 2.2863 - acc: 0.2761\n",
      "Epoch 15/100\n",
      "59/59 [==============================] - 0s 625us/step - loss: 2.2766 - acc: 0.2754\n",
      "Epoch 16/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 2.2634 - acc: 0.2825\n",
      "Epoch 17/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 2.2467 - acc: 0.2832\n",
      "Epoch 18/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 2.2376 - acc: 0.2936\n",
      "Epoch 19/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 2.2181 - acc: 0.3002\n",
      "Epoch 20/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 2.2124 - acc: 0.2963\n",
      "Epoch 21/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 2.1915 - acc: 0.3035\n",
      "Epoch 22/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 2.1764 - acc: 0.3040\n",
      "Epoch 23/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 2.1677 - acc: 0.3118\n",
      "Epoch 24/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 2.1507 - acc: 0.3205\n",
      "Epoch 25/100\n",
      "59/59 [==============================] - 0s 575us/step - loss: 2.1360 - acc: 0.3176\n",
      "Epoch 26/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 2.1230 - acc: 0.3223\n",
      "Epoch 27/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 2.1076 - acc: 0.3271\n",
      "Epoch 28/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 2.0966 - acc: 0.3322\n",
      "Epoch 29/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 2.0788 - acc: 0.3328\n",
      "Epoch 30/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 2.0621 - acc: 0.3452\n",
      "Epoch 31/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 2.0508 - acc: 0.3461\n",
      "Epoch 32/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 2.0335 - acc: 0.3508\n",
      "Epoch 33/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 2.0221 - acc: 0.3560\n",
      "Epoch 34/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.9983 - acc: 0.3690\n",
      "Epoch 35/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 1.9899 - acc: 0.3667\n",
      "Epoch 36/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.9732 - acc: 0.3709\n",
      "Epoch 37/100\n",
      "59/59 [==============================] - 0s 610us/step - loss: 1.9544 - acc: 0.3702\n",
      "Epoch 38/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 1.9410 - acc: 0.3815\n",
      "Epoch 39/100\n",
      "59/59 [==============================] - 0s 625us/step - loss: 1.9221 - acc: 0.3871\n",
      "Epoch 40/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 1.9159 - acc: 0.3896\n",
      "Epoch 41/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 1.8954 - acc: 0.3932\n",
      "Epoch 42/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.8786 - acc: 0.4009\n",
      "Epoch 43/100\n",
      "59/59 [==============================] - 0s 575us/step - loss: 1.8640 - acc: 0.4030\n",
      "Epoch 44/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.8507 - acc: 0.4052\n",
      "Epoch 45/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 1.8263 - acc: 0.4211\n",
      "Epoch 46/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 1.8184 - acc: 0.4188\n",
      "Epoch 47/100\n",
      "59/59 [==============================] - 0s 615us/step - loss: 1.8021 - acc: 0.4186\n",
      "Epoch 48/100\n",
      "59/59 [==============================] - 0s 600us/step - loss: 1.7817 - acc: 0.4325\n",
      "Epoch 49/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.7631 - acc: 0.4352\n",
      "Epoch 50/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 1.7556 - acc: 0.4419\n",
      "Epoch 51/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.7374 - acc: 0.4421\n",
      "Epoch 52/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.7213 - acc: 0.4522\n",
      "Epoch 53/100\n",
      "59/59 [==============================] - 0s 625us/step - loss: 1.6978 - acc: 0.4578\n",
      "Epoch 54/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 1.6891 - acc: 0.4594\n",
      "Epoch 55/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.6753 - acc: 0.4684\n",
      "Epoch 56/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 1.6637 - acc: 0.4671\n",
      "Epoch 57/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.6396 - acc: 0.4792\n",
      "Epoch 58/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 1.6307 - acc: 0.4819\n",
      "Epoch 59/100\n",
      "59/59 [==============================] - 0s 597us/step - loss: 1.6212 - acc: 0.4854\n",
      "Epoch 60/100\n",
      "59/59 [==============================] - 0s 575us/step - loss: 1.6007 - acc: 0.4881\n",
      "Epoch 61/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.5936 - acc: 0.4854\n",
      "Epoch 62/100\n",
      "59/59 [==============================] - 0s 628us/step - loss: 1.5645 - acc: 0.5066\n",
      "Epoch 63/100\n",
      "59/59 [==============================] - 0s 612us/step - loss: 1.5513 - acc: 0.5095\n",
      "Epoch 64/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.5452 - acc: 0.5123\n",
      "Epoch 65/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 1.5306 - acc: 0.5173\n",
      "Epoch 66/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.5150 - acc: 0.5209\n",
      "Epoch 67/100\n",
      "59/59 [==============================] - 0s 600us/step - loss: 1.5078 - acc: 0.5192\n",
      "Epoch 68/100\n",
      "59/59 [==============================] - 0s 616us/step - loss: 1.4831 - acc: 0.5321\n",
      "Epoch 69/100\n",
      "59/59 [==============================] - 0s 610us/step - loss: 1.4719 - acc: 0.5340\n",
      "Epoch 70/100\n",
      "59/59 [==============================] - 0s 558us/step - loss: 1.4620 - acc: 0.5334\n",
      "Epoch 71/100\n",
      "59/59 [==============================] - 0s 616us/step - loss: 1.4432 - acc: 0.5386\n",
      "Epoch 72/100\n",
      "59/59 [==============================] - 0s 575us/step - loss: 1.4266 - acc: 0.5489\n",
      "Epoch 73/100\n",
      "59/59 [==============================] - 0s 575us/step - loss: 1.4211 - acc: 0.5442\n",
      "Epoch 74/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.4059 - acc: 0.5550\n",
      "Epoch 75/100\n",
      "59/59 [==============================] - 0s 595us/step - loss: 1.3923 - acc: 0.5588\n",
      "Epoch 76/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 1.3800 - acc: 0.5627\n",
      "Epoch 77/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 1.3623 - acc: 0.5654\n",
      "Epoch 78/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.3519 - acc: 0.5714\n",
      "Epoch 79/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.3450 - acc: 0.5758\n",
      "Epoch 80/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 1.3312 - acc: 0.5743\n",
      "Epoch 81/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.3055 - acc: 0.5832\n",
      "Epoch 82/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.3063 - acc: 0.5852\n",
      "Epoch 83/100\n",
      "59/59 [==============================] - 0s 575us/step - loss: 1.2884 - acc: 0.5951\n",
      "Epoch 84/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.2751 - acc: 0.5943\n",
      "Epoch 85/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.2689 - acc: 0.5975\n",
      "Epoch 86/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.2539 - acc: 0.5997\n",
      "Epoch 87/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.2364 - acc: 0.6085\n",
      "Epoch 88/100\n",
      "59/59 [==============================] - 0s 575us/step - loss: 1.2236 - acc: 0.6118\n",
      "Epoch 89/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.2138 - acc: 0.6160\n",
      "Epoch 90/100\n",
      "59/59 [==============================] - 0s 609us/step - loss: 1.2111 - acc: 0.6167\n",
      "Epoch 91/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.1896 - acc: 0.6222\n",
      "Epoch 92/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.1792 - acc: 0.6195\n",
      "Epoch 93/100\n",
      "59/59 [==============================] - 0s 575us/step - loss: 1.1593 - acc: 0.6305\n",
      "Epoch 94/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.1512 - acc: 0.6366\n",
      "Epoch 95/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.1432 - acc: 0.6365\n",
      "Epoch 96/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 1.1209 - acc: 0.6508\n",
      "Epoch 97/100\n",
      "59/59 [==============================] - 0s 575us/step - loss: 1.1153 - acc: 0.6505\n",
      "Epoch 98/100\n",
      "59/59 [==============================] - 0s 575us/step - loss: 1.1039 - acc: 0.6515\n",
      "Epoch 99/100\n",
      "59/59 [==============================] - 0s 575us/step - loss: 1.0946 - acc: 0.6562\n",
      "Epoch 100/100\n",
      "59/59 [==============================] - 0s 575us/step - loss: 1.0811 - acc: 0.6595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20ffc7962e0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch = 128\n",
    "my_nn.compile(loss='sparse_categorical_crossentropy',optimizer='RMSProp',\n",
    "              metrics=['acc'])\n",
    "my_nn.fit(x_tr, y_tr, batch_size=batch, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 345us/step - loss: 3.8940 - acc: 0.1760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.8939826488494873, 0.1759742796421051]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_nn.evaluate(val_x_tr, val_y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = my_nn.predict(test_tr)\n",
    "pred_class = [idx2class[i] for i in pred.argmax(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(pred_class, index=test.index, columns=['PRED']).reset_index()\n",
    "submission.to_csv('my_pred02.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AutoEncoder 사용 : 과소완전AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 64)                9728      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 151)               9815      \n",
      "=================================================================\n",
      "Total params: 19,543\n",
      "Trainable params: 19,543\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_dim = 64\n",
    "autoE = Sequential([\n",
    "            Input(shape=(x_tr.shape[1],)),\n",
    "            Dense(num_dim, activation='relu'),\n",
    "            Dense(x_tr.shape[1], activation='relu')])\n",
    "autoE.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "59/59 [==============================] - 0s 654us/step - loss: 0.0944 - mse: 0.0944\n",
      "Epoch 2/100\n",
      "59/59 [==============================] - 0s 540us/step - loss: 0.0633 - mse: 0.0633\n",
      "Epoch 3/100\n",
      "59/59 [==============================] - 0s 552us/step - loss: 0.0523 - mse: 0.0523\n",
      "Epoch 4/100\n",
      "59/59 [==============================] - 0s 567us/step - loss: 0.0460 - mse: 0.0460\n",
      "Epoch 5/100\n",
      "59/59 [==============================] - 0s 566us/step - loss: 0.0421 - mse: 0.0421\n",
      "Epoch 6/100\n",
      "59/59 [==============================] - 0s 558us/step - loss: 0.0394 - mse: 0.0394\n",
      "Epoch 7/100\n",
      "59/59 [==============================] - 0s 558us/step - loss: 0.0374 - mse: 0.0374\n",
      "Epoch 8/100\n",
      "59/59 [==============================] - 0s 553us/step - loss: 0.0320 - mse: 0.0320\n",
      "Epoch 9/100\n",
      "59/59 [==============================] - 0s 541us/step - loss: 0.0304 - mse: 0.0304\n",
      "Epoch 10/100\n",
      "59/59 [==============================] - 0s 578us/step - loss: 0.0291 - mse: 0.0291\n",
      "Epoch 11/100\n",
      "59/59 [==============================] - 0s 558us/step - loss: 0.0282 - mse: 0.0282\n",
      "Epoch 12/100\n",
      "59/59 [==============================] - 0s 540us/step - loss: 0.0274 - mse: 0.0274\n",
      "Epoch 13/100\n",
      "59/59 [==============================] - 0s 558us/step - loss: 0.0268 - mse: 0.0268\n",
      "Epoch 14/100\n",
      "59/59 [==============================] - 0s 574us/step - loss: 0.0262 - mse: 0.0262\n",
      "Epoch 15/100\n",
      "59/59 [==============================] - 0s 541us/step - loss: 0.0258 - mse: 0.0258\n",
      "Epoch 16/100\n",
      "59/59 [==============================] - 0s 575us/step - loss: 0.0254 - mse: 0.0254\n",
      "Epoch 17/100\n",
      "59/59 [==============================] - 0s 552us/step - loss: 0.0250 - mse: 0.0250\n",
      "Epoch 18/100\n",
      "59/59 [==============================] - 0s 552us/step - loss: 0.0243 - mse: 0.0243\n",
      "Epoch 19/100\n",
      "59/59 [==============================] - 0s 577us/step - loss: 0.0238 - mse: 0.0238\n",
      "Epoch 20/100\n",
      "59/59 [==============================] - 0s 574us/step - loss: 0.0235 - mse: 0.0235\n",
      "Epoch 21/100\n",
      "59/59 [==============================] - 0s 567us/step - loss: 0.0232 - mse: 0.0232\n",
      "Epoch 22/100\n",
      "59/59 [==============================] - 0s 555us/step - loss: 0.0230 - mse: 0.0230\n",
      "Epoch 23/100\n",
      "59/59 [==============================] - 0s 566us/step - loss: 0.0228 - mse: 0.0228\n",
      "Epoch 24/100\n",
      "59/59 [==============================] - 0s 556us/step - loss: 0.0226 - mse: 0.0226\n",
      "Epoch 25/100\n",
      "59/59 [==============================] - 0s 558us/step - loss: 0.0224 - mse: 0.0224\n",
      "Epoch 26/100\n",
      "59/59 [==============================] - 0s 563us/step - loss: 0.0223 - mse: 0.0223\n",
      "Epoch 27/100\n",
      "59/59 [==============================] - 0s 592us/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 28/100\n",
      "59/59 [==============================] - 0s 575us/step - loss: 0.0211 - mse: 0.0211\n",
      "Epoch 29/100\n",
      "59/59 [==============================] - 0s 574us/step - loss: 0.0209 - mse: 0.0209\n",
      "Epoch 30/100\n",
      "59/59 [==============================] - 0s 575us/step - loss: 0.0208 - mse: 0.0208\n",
      "Epoch 31/100\n",
      "59/59 [==============================] - 0s 565us/step - loss: 0.0207 - mse: 0.0207\n",
      "Epoch 32/100\n",
      "59/59 [==============================] - 0s 543us/step - loss: 0.0206 - mse: 0.0206\n",
      "Epoch 33/100\n",
      "59/59 [==============================] - 0s 573us/step - loss: 0.0205 - mse: 0.0205\n",
      "Epoch 34/100\n",
      "59/59 [==============================] - 0s 541us/step - loss: 0.0204 - mse: 0.0204\n",
      "Epoch 35/100\n",
      "59/59 [==============================] - 0s 541us/step - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 36/100\n",
      "59/59 [==============================] - 0s 558us/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 37/100\n",
      "59/59 [==============================] - 0s 558us/step - loss: 0.0202 - mse: 0.0202\n",
      "Epoch 38/100\n",
      "59/59 [==============================] - 0s 541us/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 39/100\n",
      "59/59 [==============================] - 0s 565us/step - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 40/100\n",
      "59/59 [==============================] - 0s 568us/step - loss: 0.0200 - mse: 0.0200\n",
      "Epoch 41/100\n",
      "59/59 [==============================] - 0s 560us/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 42/100\n",
      "59/59 [==============================] - 0s 535us/step - loss: 0.0199 - mse: 0.0199\n",
      "Epoch 43/100\n",
      "59/59 [==============================] - 0s 558us/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 44/100\n",
      "59/59 [==============================] - 0s 558us/step - loss: 0.0198 - mse: 0.0198\n",
      "Epoch 45/100\n",
      "59/59 [==============================] - 0s 564us/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 46/100\n",
      "59/59 [==============================] - 0s 559us/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 47/100\n",
      "59/59 [==============================] - 0s 557us/step - loss: 0.0197 - mse: 0.0197\n",
      "Epoch 48/100\n",
      "59/59 [==============================] - 0s 557us/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 49/100\n",
      "59/59 [==============================] - 0s 585us/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 50/100\n",
      "59/59 [==============================] - 0s 574us/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 51/100\n",
      "59/59 [==============================] - 0s 574us/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 52/100\n",
      "59/59 [==============================] - 0s 569us/step - loss: 0.0195 - mse: 0.0195\n",
      "Epoch 53/100\n",
      "59/59 [==============================] - 0s 555us/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 54/100\n",
      "59/59 [==============================] - 0s 562us/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 55/100\n",
      "59/59 [==============================] - 0s 557us/step - loss: 0.0194 - mse: 0.0194\n",
      "Epoch 56/100\n",
      "59/59 [==============================] - 0s 552us/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 57/100\n",
      "59/59 [==============================] - 0s 558us/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 58/100\n",
      "59/59 [==============================] - 0s 540us/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 59/100\n",
      "59/59 [==============================] - 0s 551us/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 60/100\n",
      "59/59 [==============================] - 0s 558us/step - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 61/100\n",
      "59/59 [==============================] - 0s 573us/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 62/100\n",
      "59/59 [==============================] - 0s 553us/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 63/100\n",
      "59/59 [==============================] - 0s 574us/step - loss: 0.0192 - mse: 0.0192\n",
      "Epoch 64/100\n",
      "59/59 [==============================] - 0s 531us/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 65/100\n",
      "59/59 [==============================] - 0s 551us/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 66/100\n",
      "59/59 [==============================] - 0s 574us/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 67/100\n",
      "59/59 [==============================] - 0s 524us/step - loss: 0.0191 - mse: 0.0191\n",
      "Epoch 68/100\n",
      "59/59 [==============================] - 0s 543us/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 69/100\n",
      "59/59 [==============================] - 0s 558us/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 70/100\n",
      "59/59 [==============================] - 0s 554us/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 71/100\n",
      "59/59 [==============================] - 0s 552us/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 72/100\n",
      "59/59 [==============================] - 0s 557us/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 73/100\n",
      "59/59 [==============================] - 0s 547us/step - loss: 0.0190 - mse: 0.0190\n",
      "Epoch 74/100\n",
      "59/59 [==============================] - 0s 557us/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 75/100\n",
      "59/59 [==============================] - 0s 541us/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 76/100\n",
      "59/59 [==============================] - 0s 534us/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 77/100\n",
      "59/59 [==============================] - 0s 559us/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 78/100\n",
      "59/59 [==============================] - 0s 558us/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 79/100\n",
      "59/59 [==============================] - 0s 540us/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 80/100\n",
      "59/59 [==============================] - 0s 534us/step - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 81/100\n",
      "59/59 [==============================] - 0s 541us/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 82/100\n",
      "59/59 [==============================] - 0s 539us/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 83/100\n",
      "59/59 [==============================] - 0s 560us/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 84/100\n",
      "59/59 [==============================] - 0s 558us/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 85/100\n",
      "59/59 [==============================] - 0s 558us/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 86/100\n",
      "59/59 [==============================] - 0s 541us/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 87/100\n",
      "59/59 [==============================] - 0s 544us/step - loss: 0.0188 - mse: 0.0188\n",
      "Epoch 88/100\n",
      "59/59 [==============================] - 0s 561us/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 89/100\n",
      "59/59 [==============================] - 0s 575us/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 90/100\n",
      "59/59 [==============================] - 0s 543us/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 91/100\n",
      "59/59 [==============================] - 0s 557us/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 92/100\n",
      "59/59 [==============================] - 0s 575us/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 93/100\n",
      "59/59 [==============================] - 0s 541us/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 94/100\n",
      "59/59 [==============================] - 0s 562us/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 95/100\n",
      "59/59 [==============================] - 0s 541us/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 96/100\n",
      "59/59 [==============================] - 0s 557us/step - loss: 0.0187 - mse: 0.0187\n",
      "Epoch 97/100\n",
      "59/59 [==============================] - 0s 557us/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 98/100\n",
      "59/59 [==============================] - 0s 547us/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 99/100\n",
      "59/59 [==============================] - 0s 541us/step - loss: 0.0186 - mse: 0.0186\n",
      "Epoch 100/100\n",
      "59/59 [==============================] - 0s 552us/step - loss: 0.0186 - mse: 0.0186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20ffe237b50>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch = 128\n",
    "autoE.compile(loss='mean_squared_error',optimizer='RMSProp',\n",
    "              metrics=['mse'])\n",
    "autoE.fit(x_tr, x_tr, batch_size=128, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_model = Model(inputs=autoE.input, outputs=autoE.layers[0].output)\n",
    "x_auto = active_model.predict(x_tr)\n",
    "val_x_auto = active_model.predict(val_x_tr)\n",
    "test_auto = active_model.predict(test_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 48)                3120      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 20)                660       \n",
      "=================================================================\n",
      "Total params: 5,348\n",
      "Trainable params: 5,348\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_nn02 = Sequential([\n",
    "            Input(shape=(x_auto.shape[1],)),\n",
    "            Dense(48, activation='relu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(y_tr.nunique(), activation='softmax')\n",
    "    ])\n",
    "my_nn02.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "59/59 [==============================] - 0s 473us/step - loss: 2.8347 - acc: 0.1305\n",
      "Epoch 2/100\n",
      "59/59 [==============================] - 0s 437us/step - loss: 2.7168 - acc: 0.1507\n",
      "Epoch 3/100\n",
      "59/59 [==============================] - 0s 452us/step - loss: 2.6543 - acc: 0.1692\n",
      "Epoch 4/100\n",
      "59/59 [==============================] - 0s 429us/step - loss: 2.6111 - acc: 0.1768\n",
      "Epoch 5/100\n",
      "59/59 [==============================] - 0s 448us/step - loss: 2.5782 - acc: 0.1882\n",
      "Epoch 6/100\n",
      "59/59 [==============================] - 0s 473us/step - loss: 2.5514 - acc: 0.1895\n",
      "Epoch 7/100\n",
      "59/59 [==============================] - 0s 439us/step - loss: 2.5298 - acc: 0.1960\n",
      "Epoch 8/100\n",
      "59/59 [==============================] - 0s 440us/step - loss: 2.5125 - acc: 0.1984\n",
      "Epoch 9/100\n",
      "59/59 [==============================] - 0s 431us/step - loss: 2.5010 - acc: 0.2053\n",
      "Epoch 10/100\n",
      "59/59 [==============================] - 0s 440us/step - loss: 2.4893 - acc: 0.2079\n",
      "Epoch 11/100\n",
      "59/59 [==============================] - 0s 443us/step - loss: 2.4791 - acc: 0.2092\n",
      "Epoch 12/100\n",
      "59/59 [==============================] - 0s 449us/step - loss: 2.4711 - acc: 0.2115\n",
      "Epoch 13/100\n",
      "59/59 [==============================] - 0s 418us/step - loss: 2.4619 - acc: 0.2155\n",
      "Epoch 14/100\n",
      "59/59 [==============================] - 0s 444us/step - loss: 2.4588 - acc: 0.2152\n",
      "Epoch 15/100\n",
      "59/59 [==============================] - 0s 423us/step - loss: 2.4509 - acc: 0.2214\n",
      "Epoch 16/100\n",
      "59/59 [==============================] - 0s 442us/step - loss: 2.4453 - acc: 0.2177\n",
      "Epoch 17/100\n",
      "59/59 [==============================] - 0s 439us/step - loss: 2.4409 - acc: 0.2248\n",
      "Epoch 18/100\n",
      "59/59 [==============================] - 0s 440us/step - loss: 2.4327 - acc: 0.2221\n",
      "Epoch 19/100\n",
      "59/59 [==============================] - 0s 440us/step - loss: 2.4326 - acc: 0.2239\n",
      "Epoch 20/100\n",
      "59/59 [==============================] - 0s 440us/step - loss: 2.4268 - acc: 0.2282\n",
      "Epoch 21/100\n",
      "59/59 [==============================] - 0s 440us/step - loss: 2.4237 - acc: 0.2266\n",
      "Epoch 22/100\n",
      "59/59 [==============================] - 0s 423us/step - loss: 2.4210 - acc: 0.2278\n",
      "Epoch 23/100\n",
      "59/59 [==============================] - 0s 439us/step - loss: 2.4162 - acc: 0.2290\n",
      "Epoch 24/100\n",
      "59/59 [==============================] - 0s 423us/step - loss: 2.4129 - acc: 0.2329\n",
      "Epoch 25/100\n",
      "59/59 [==============================] - 0s 464us/step - loss: 2.4117 - acc: 0.2285\n",
      "Epoch 26/100\n",
      "59/59 [==============================] - 0s 456us/step - loss: 2.4082 - acc: 0.2320\n",
      "Epoch 27/100\n",
      "59/59 [==============================] - 0s 440us/step - loss: 2.4041 - acc: 0.2297\n",
      "Epoch 28/100\n",
      "59/59 [==============================] - 0s 446us/step - loss: 2.4013 - acc: 0.2313\n",
      "Epoch 29/100\n",
      "59/59 [==============================] - 0s 456us/step - loss: 2.3978 - acc: 0.2308\n",
      "Epoch 30/100\n",
      "59/59 [==============================] - 0s 446us/step - loss: 2.3977 - acc: 0.2348\n",
      "Epoch 31/100\n",
      "59/59 [==============================] - 0s 441us/step - loss: 2.3957 - acc: 0.2356\n",
      "Epoch 32/100\n",
      "59/59 [==============================] - 0s 423us/step - loss: 2.3926 - acc: 0.2351\n",
      "Epoch 33/100\n",
      "59/59 [==============================] - 0s 427us/step - loss: 2.3901 - acc: 0.2344\n",
      "Epoch 34/100\n",
      "59/59 [==============================] - 0s 445us/step - loss: 2.3869 - acc: 0.2375\n",
      "Epoch 35/100\n",
      "59/59 [==============================] - 0s 458us/step - loss: 2.3843 - acc: 0.2372\n",
      "Epoch 36/100\n",
      "59/59 [==============================] - 0s 456us/step - loss: 2.3823 - acc: 0.2356\n",
      "Epoch 37/100\n",
      "59/59 [==============================] - 0s 425us/step - loss: 2.3804 - acc: 0.2364\n",
      "Epoch 38/100\n",
      "59/59 [==============================] - 0s 439us/step - loss: 2.3779 - acc: 0.2383\n",
      "Epoch 39/100\n",
      "59/59 [==============================] - 0s 440us/step - loss: 2.3759 - acc: 0.2414\n",
      "Epoch 40/100\n",
      "59/59 [==============================] - 0s 439us/step - loss: 2.3728 - acc: 0.2412\n",
      "Epoch 41/100\n",
      "59/59 [==============================] - 0s 424us/step - loss: 2.3722 - acc: 0.2428\n",
      "Epoch 42/100\n",
      "59/59 [==============================] - 0s 444us/step - loss: 2.3701 - acc: 0.2395\n",
      "Epoch 43/100\n",
      "59/59 [==============================] - 0s 428us/step - loss: 2.3670 - acc: 0.2416\n",
      "Epoch 44/100\n",
      "59/59 [==============================] - 0s 440us/step - loss: 2.3674 - acc: 0.2469\n",
      "Epoch 45/100\n",
      "59/59 [==============================] - 0s 423us/step - loss: 2.3627 - acc: 0.2428\n",
      "Epoch 46/100\n",
      "59/59 [==============================] - 0s 423us/step - loss: 2.3644 - acc: 0.2399\n",
      "Epoch 47/100\n",
      "59/59 [==============================] - 0s 439us/step - loss: 2.3599 - acc: 0.2447\n",
      "Epoch 48/100\n",
      "59/59 [==============================] - 0s 423us/step - loss: 2.3590 - acc: 0.2444\n",
      "Epoch 49/100\n",
      "59/59 [==============================] - 0s 423us/step - loss: 2.3557 - acc: 0.2438\n",
      "Epoch 50/100\n",
      "59/59 [==============================] - 0s 434us/step - loss: 2.3538 - acc: 0.2428\n",
      "Epoch 51/100\n",
      "59/59 [==============================] - 0s 440us/step - loss: 2.3531 - acc: 0.2459\n",
      "Epoch 52/100\n",
      "59/59 [==============================] - 0s 443us/step - loss: 2.3503 - acc: 0.2487\n",
      "Epoch 53/100\n",
      "59/59 [==============================] - 0s 423us/step - loss: 2.3464 - acc: 0.2490\n",
      "Epoch 54/100\n",
      "59/59 [==============================] - 0s 440us/step - loss: 2.3465 - acc: 0.2490\n",
      "Epoch 55/100\n",
      "59/59 [==============================] - 0s 423us/step - loss: 2.3438 - acc: 0.2474\n",
      "Epoch 56/100\n",
      "59/59 [==============================] - 0s 439us/step - loss: 2.3435 - acc: 0.2503\n",
      "Epoch 57/100\n",
      "59/59 [==============================] - 0s 445us/step - loss: 2.3415 - acc: 0.2522\n",
      "Epoch 58/100\n",
      "59/59 [==============================] - 0s 423us/step - loss: 2.3391 - acc: 0.2545\n",
      "Epoch 59/100\n",
      "59/59 [==============================] - 0s 436us/step - loss: 2.3358 - acc: 0.2549\n",
      "Epoch 60/100\n",
      "59/59 [==============================] - 0s 440us/step - loss: 2.3360 - acc: 0.2545\n",
      "Epoch 61/100\n",
      "59/59 [==============================] - 0s 431us/step - loss: 2.3336 - acc: 0.2560\n",
      "Epoch 62/100\n",
      "59/59 [==============================] - 0s 460us/step - loss: 2.3323 - acc: 0.2548\n",
      "Epoch 63/100\n",
      "59/59 [==============================] - 0s 423us/step - loss: 2.3313 - acc: 0.2566\n",
      "Epoch 64/100\n",
      "59/59 [==============================] - 0s 435us/step - loss: 2.3301 - acc: 0.2569\n",
      "Epoch 65/100\n",
      "59/59 [==============================] - 0s 419us/step - loss: 2.3281 - acc: 0.2546\n",
      "Epoch 66/100\n",
      "59/59 [==============================] - 0s 439us/step - loss: 2.3250 - acc: 0.2578\n",
      "Epoch 67/100\n",
      "59/59 [==============================] - 0s 423us/step - loss: 2.3238 - acc: 0.2586\n",
      "Epoch 68/100\n",
      "59/59 [==============================] - 0s 423us/step - loss: 2.3229 - acc: 0.2582\n",
      "Epoch 69/100\n",
      "59/59 [==============================] - 0s 431us/step - loss: 2.3209 - acc: 0.2557\n",
      "Epoch 70/100\n",
      "59/59 [==============================] - 0s 422us/step - loss: 2.3189 - acc: 0.2606\n",
      "Epoch 71/100\n",
      "59/59 [==============================] - 0s 456us/step - loss: 2.3169 - acc: 0.2588\n",
      "Epoch 72/100\n",
      "59/59 [==============================] - 0s 440us/step - loss: 2.3162 - acc: 0.2609\n",
      "Epoch 73/100\n",
      "59/59 [==============================] - 0s 433us/step - loss: 2.3142 - acc: 0.2613\n",
      "Epoch 74/100\n",
      "59/59 [==============================] - 0s 440us/step - loss: 2.3141 - acc: 0.2611\n",
      "Epoch 75/100\n",
      "59/59 [==============================] - 0s 441us/step - loss: 2.3106 - acc: 0.2664\n",
      "Epoch 76/100\n",
      "59/59 [==============================] - 0s 422us/step - loss: 2.3076 - acc: 0.2619\n",
      "Epoch 77/100\n",
      "59/59 [==============================] - 0s 428us/step - loss: 2.3066 - acc: 0.2616\n",
      "Epoch 78/100\n",
      "59/59 [==============================] - 0s 443us/step - loss: 2.3048 - acc: 0.2633\n",
      "Epoch 79/100\n",
      "59/59 [==============================] - 0s 423us/step - loss: 2.3054 - acc: 0.2636\n",
      "Epoch 80/100\n",
      "59/59 [==============================] - 0s 439us/step - loss: 2.3036 - acc: 0.2668\n",
      "Epoch 81/100\n",
      "59/59 [==============================] - 0s 423us/step - loss: 2.3000 - acc: 0.2696\n",
      "Epoch 82/100\n",
      "59/59 [==============================] - 0s 424us/step - loss: 2.2994 - acc: 0.2639\n",
      "Epoch 83/100\n",
      "59/59 [==============================] - 0s 432us/step - loss: 2.2956 - acc: 0.2703\n",
      "Epoch 84/100\n",
      "59/59 [==============================] - 0s 440us/step - loss: 2.2963 - acc: 0.2643\n",
      "Epoch 85/100\n",
      "59/59 [==============================] - 0s 440us/step - loss: 2.2933 - acc: 0.2669\n",
      "Epoch 86/100\n",
      "59/59 [==============================] - 0s 440us/step - loss: 2.2922 - acc: 0.2673\n",
      "Epoch 87/100\n",
      "59/59 [==============================] - 0s 423us/step - loss: 2.2899 - acc: 0.2703\n",
      "Epoch 88/100\n",
      "59/59 [==============================] - 0s 439us/step - loss: 2.2886 - acc: 0.2712\n",
      "Epoch 89/100\n",
      "59/59 [==============================] - 0s 427us/step - loss: 2.2868 - acc: 0.2702\n",
      "Epoch 90/100\n",
      "59/59 [==============================] - 0s 439us/step - loss: 2.2859 - acc: 0.2736\n",
      "Epoch 91/100\n",
      "59/59 [==============================] - 0s 423us/step - loss: 2.2841 - acc: 0.2712\n",
      "Epoch 92/100\n",
      "59/59 [==============================] - 0s 423us/step - loss: 2.2822 - acc: 0.2707\n",
      "Epoch 93/100\n",
      "59/59 [==============================] - 0s 423us/step - loss: 2.2804 - acc: 0.2720\n",
      "Epoch 94/100\n",
      "59/59 [==============================] - 0s 433us/step - loss: 2.2807 - acc: 0.2748\n",
      "Epoch 95/100\n",
      "59/59 [==============================] - 0s 443us/step - loss: 2.2786 - acc: 0.2742\n",
      "Epoch 96/100\n",
      "59/59 [==============================] - 0s 423us/step - loss: 2.2763 - acc: 0.2700\n",
      "Epoch 97/100\n",
      "59/59 [==============================] - 0s 423us/step - loss: 2.2758 - acc: 0.2722\n",
      "Epoch 98/100\n",
      "59/59 [==============================] - 0s 440us/step - loss: 2.2738 - acc: 0.2754\n",
      "Epoch 99/100\n",
      "59/59 [==============================] - 0s 426us/step - loss: 2.2706 - acc: 0.2766\n",
      "Epoch 100/100\n",
      "59/59 [==============================] - 0s 431us/step - loss: 2.2681 - acc: 0.2773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20f8018f520>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch = 128\n",
    "my_nn02.compile(loss='sparse_categorical_crossentropy',optimizer='RMSProp',\n",
    "              metrics=['acc'])\n",
    "my_nn02.fit(x_auto, y_tr, batch_size=batch, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 345us/step - loss: 2.5374 - acc: 0.2001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5374293327331543, 0.20008035004138947]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_nn02.evaluate(val_x_auto, val_y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = my_nn02.predict(test_auto)\n",
    "pred_class = [idx2class[i] for i in pred.argmax(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(pred_class, index=test.index, columns=['PRED']).reset_index()\n",
    "submission.to_csv('my_pred03.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
